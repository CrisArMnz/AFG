# -*- coding: utf-8 -*-
"""streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pgKAUoma9-cSH3hkkNNGnxzNgEgSAZxb
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import os
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout

import yaml
import datetime
import sys
from src.data_downloader.data_downloader import DataDawnLoader
from src.data_process.data_process import DataProcess

import sys
sys.path.append(r"./src")  # Ajusta esta ruta seg칰n la estructura de tu proyecto
from data_downloader.data_downloader import DataDawnLoader
from src.bar_char.bar_chart import render_bar_chart

# Funci칩n para cargar los datos
@st.cache_data
def load_data(file_path):
    if not os.path.exists(file_path):
        st.error(f"El archivo no se encuentra en la ruta: {file_path}")
        st.stop()
    df = pd.read_parquet(file_path)
    df['Fecha_Semana'] = pd.to_datetime(df['Fecha_Semana'])
    return df

# Preprocesar los datos
def preprocess_data(df, selected_regions, start_week, end_week):
    df_filtered = df[(df['NombreRegion'].isin(selected_regions)) &
                     (df['Fecha_Semana'] >= start_week) &
                     (df['Fecha_Semana'] <= end_week)]
    df_filtered = df_filtered[['Fecha_Semana', 'Total_per_capita_2019']].sort_values('Fecha_Semana')
    df_filtered.set_index('Fecha_Semana', inplace=True)
    scaler = MinMaxScaler(feature_range=(0, 1))
    data_scaled = scaler.fit_transform(df_filtered)
    return df_filtered, data_scaled, scaler

# Crear secuencias para el modelo LSTM
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

# Obtener estad칤sticas adicionales
def get_statistics(df_filtered, future_predictions_rescaled, future_dates):
    current_week = df_filtered.index[-1]
    last_year_week = current_week - pd.Timedelta(weeks=52)

    current_month = current_week.month
    last_year_month = current_month

    # Valores espec칤ficos
    current_week_value = df_filtered.loc[current_week, 'Total_per_capita_2019']
    last_year_week_value = df_filtered.loc[last_year_week, 'Total_per_capita_2019'] if last_year_week in df_filtered.index else None

    # Promedios mensuales
    current_month_avg = df_filtered[df_filtered.index.month == current_month]['Total_per_capita_2019'].mean()
    last_year_month_avg = df_filtered[(df_filtered.index.month == last_year_month) &
                                       (df_filtered.index.year == current_week.year - 1)]['Total_per_capita_2019'].mean()

    # Predicciones futuras
    future_values = dict(zip(future_dates.strftime("%Y-%m-%d"), future_predictions_rescaled.flatten()))

    return current_week_value, last_year_week_value, current_month_avg, last_year_month_avg, future_values

# Mostrar estad칤sticas en una tabla
def display_statistics(current_week_value, last_year_week_value, current_month_avg, last_year_month_avg, future_values):
    stats_data = {
        "Descripci칩n": [
            "Valor real de la semana en curso",
            "Valor real de la misma semana el a침o anterior",
            "Promedio del mes en curso",
            "Promedio del mismo mes el a침o anterior"
        ],
        "Valor": [
            f"{current_week_value:.6f}",
            f"{last_year_week_value:.6f}" if last_year_week_value else "No disponible",
            f"{current_month_avg:.6f}",
            f"{last_year_month_avg:.6f}"
        ]
    }

    future_data = {
        "Semana": list(future_values.keys()),
        "Predicci칩n": [f"{value:.6f}" for value in future_values.values()]
    }

    st.write("### Resumen de Estad칤sticas")
    st.table(pd.DataFrame(stats_data))  # Estad칤sticas generales
    st.write("### Predicciones para las pr칩ximas 4 semanas")
    st.table(pd.DataFrame(future_data))  # Predicciones futuras

# Define la funci칩n que actualiza la base de datos
def actualizar_base_datos():
    # Aqu칤 incluyes el c칩digo para actualizar la base de datos
    # Por ejemplo, puedes cargar, modificar y guardar un archivo Excel
    #archivo = "base_datos.xlsx"  # Ruta al archivo Excel
    try:
        with open("./assets/app_settings.yaml", 'r', encoding='utf-8') as file:
            app_settings = yaml.safe_load(file)
        data = DataDawnLoader(app_settings["DATA"])
        process = DataProcess(app_settings)

        df = pd.read_parquet(app_settings["PROCESS"]["OUT_DIR"] + app_settings["PROCESS"]["OUT_FILE_NAME"])
        current_week =  int(datetime.datetime.now().isocalendar().week)
        current_year =  int(datetime.datetime.now().isocalendar().year)
        df = df[df["Fecha_Semana"].dt.isocalendar().year == current_year]
        if not df.empty:
            last_week = pd.to_datetime(df["Fecha_Semana"]).dt.isocalendar().week.max()
            last_year = pd.to_datetime(df["Fecha_Semana"]).dt.isocalendar().year.max()
            print(f"Ultima semana del a침o descargada {last_week} - semana actual {current_week}")
            if (current_week > last_week) | (last_year < current_year):
                process.get_filter_data(force_process=False)
                data.update_current_year_data()
                process.update_data()
            else:
                print("DATOS ESTAN ACTUALIZADOS")
        else:
            process.get_filter_data(force_process=False)
            data.update_current_year_data()
            process.update_data()
    except Exception as e:
        st.error(f"Error al actualizar la base de datos: {e}")


# Funci칩n principal
def main():
    with open("./assets/app_settings.yaml", 'r', encoding='utf-8') as file:
        app_settings = yaml.safe_load(file)

    st.title("Dashboard: Predicci칩n de Urgencias Respiratorias per C치pita")
    st.subheader("Serie de tiempo filtrada por regi칩n y rango de semanas")

    # Agregar el bot칩n
    if st.sidebar.button("Actualizar Base de Datos"):
        actualizar_base_datos()
    # Ruta al archivo
    #file_path = "/Users/erickgarciaviveros/Library/CloudStorage/OneDrive-Personal/a_PUC_/MCD_b10_Actividad de Graduacio패n III/Streamlit/UR/df_semanal_regional.xlsx"
    file_path = app_settings["PROCESS"]["OUT_DIR"] + app_settings["PROCESS"]["OUT_FILE_NAME"]

    df = load_data(file_path)

    # Filtros interactivos
    st.sidebar.header("Filtros")
    regiones = df['NombreRegion'].unique()
    #selected_regions = st.sidebar.multiselect("Selecciona las regiones:", regiones, default=regiones)
    selected_regions = st.sidebar.multiselect("Selecciona las regiones:", regiones, default=["Metropolitana de Santiago"])

    st.sidebar.header("Rango de Semanas")
    min_date = df['Fecha_Semana'].min()
    max_date = df['Fecha_Semana'].max()
    weeks = pd.date_range(start=min_date, end=max_date, freq='W')
    start_week, end_week = st.sidebar.select_slider(
        "Selecciona el rango de semanas:",
        options=weeks,
        value=(weeks[0], weeks[-1])
    )
    seq_length = st.sidebar.slider("Longitud de la secuencia de entrada:", 2, 10, 5)

    # Preprocesar los datos
    df_filtered, data_scaled, scaler = preprocess_data(df, selected_regions, start_week, end_week)

    if len(df_filtered) < seq_length + 1:
        st.error("No hay suficientes datos para entrenar el modelo. Ajusta los filtros o la longitud de la secuencia.")
        return

    # Crear secuencias
    X, y = create_sequences(data_scaled, seq_length)
    X = X.reshape((X.shape[0], X.shape[1], 1))

    # Dividir en entrenamiento y prueba
    train_size = int(len(X) * 0.8)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    # Modelo LSTM
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(seq_length, 1), return_sequences=True),
        Dropout(0.2),
        LSTM(50, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')

    # Entrenar el modelo
    st.write("### Entrenando el modelo...")
    with st.spinner("Por favor espera..."):
        model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), verbose=0)
    st.success("Modelo entrenado con 칠xito!")

    # Predicci칩n y proyecciones
    y_pred = model.predict(X_test)
    y_pred_rescaled = scaler.inverse_transform(y_pred)
    future_predictions = []
    input_seq = X[-1]
    for _ in range(4):
        pred = model.predict(input_seq.reshape(1, seq_length, 1))
        future_predictions.append(pred[0, 0])
        input_seq = np.append(input_seq[1:], pred[0, 0]).reshape(seq_length, 1)
    future_predictions_rescaled = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))
    future_dates = pd.date_range(df_filtered.index[-1], periods=5, freq='W')[1:]

    # Obtener estad칤sticas
    current_week_value, last_year_week_value, current_month_avg, last_year_month_avg, future_values = get_statistics(
        df_filtered, future_predictions_rescaled, future_dates)

    # Mostrar estad칤sticas
    display_statistics(current_week_value, last_year_week_value, current_month_avg, last_year_month_avg, future_values)

    # Gr치fico
    st.write("### Comparaci칩n de Valores Reales y Predicciones")
    fig = px.line(df_filtered.reset_index(), x='Fecha_Semana', y='Total_per_capita_2019', title="Valores Reales y Proyecciones")
    fig.add_scatter(x=future_dates, y=future_predictions_rescaled.flatten(), mode='lines+markers', name='Proyecciones Futuras')
    st.plotly_chart(fig, use_container_width=True)


    
    # Llamar al gr치fico de barras
    st.header("Gr치ficos de Atenciones por Regi칩n")
    render_bar_chart("process_data/data_filtered.parquet")
    
    # Informaci칩n adicional
    st.sidebar.header("Opciones")
    st.sidebar.markdown("""
    Este dashboard permite:
    - Visualizar las atenciones totales por regi칩n.
    - Analizar los datos procesados din치micamente.
    """)
    
    # Espacio para futuras visualizaciones
    st.markdown("### M치s visualizaciones estar치n disponibles pr칩ximamente. 游")

if __name__ == "__main__":
    main()
